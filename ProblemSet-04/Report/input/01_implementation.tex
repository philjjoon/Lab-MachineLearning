\chapter{Implementation}
\label{chap:implementation}
%#############################################################################################

This chapter explains the implementation of some algorithms that are used in this problem set. It includes: \textit{PCA}, \textit{$\gamma$-index} and \textit{LLE}.

\section{Assignment 1: SMO For SVMs}
\label{sec:assignment1}

In this assignment the function \textit{pca} has to be implemented, which receives a \textit{d x n} matrix \textit{X} and the number of components \textit{m} as parameters, and returns the principal components as well as the projected data points in a \textit{m x n} matrix \textit{Z}. The principle components should be returned as a \textit{d x d} matrix \textit{U} and a \textit{1 x d} vector \textit{D}. The vector \textit{D} contains the principal values, sorted in descending order ($D_1 \geq D_2 ...$), whereas the matrix \textit{U} contains the principal directions, which corresponds to the sorted principle values.

The implemented function was tested on the test data and passed the test. Following steps are performed in the implementation of the function:
\begin{enumerate}
	\item Substract \textit{X} from its mean.
	\item Calculate the covariance matrix from the zero-mean \textit{X}.
	\item Calculate the eigenvalues and eigenvectors from the covariance matrix.
	\item Sort the eigenvalues and eigenvectors in descending order.
	\item Form the feature vectors by taking only the first \textit{m} eigenvectors.
	\item Project the zero-mean \textit{X} to the feature vectors.
	\item Return the projected data points, principal directions and principal values as \textit{Z}, \textit{U} and \textit{D}.
\end{enumerate}

%######################################################################################
\section{Assignment 2: SVM Visualization}
\label{sec:assignment2}

The task in this assignment is to implement the $\gamma$-index which can be used to detect outliers in data set. In their paper, \citeasnoun**{Harmeling2006} formulate the formula to calculate the $\gamma$-index for each data point as follows:
\begin{equation}
	\gamma(x)=\frac{1}{k} \sum_{j=1}^{k} \| x-z_j(x) \|
\end{equation}
where $x$ is a data point, $k$ is the number of nearest neighbours, and $z_1(x),...,z_k(x)$ are the $k$ nearest neighbours of $x$.

The implemented function receives a \textit{d x n} matrix \textit{X} containing the data points and a scalar \textit{k} representing the number of neighbours as parameters. It returns the $\gamma$-index for each data point in a \textit{1 x n} vector \textit{y}.

The function was tested on the test data and passed the test. Following steps are performed in the implementation of the function:
\begin{enumerate}
	\item Implement a helper function \textit{distmat} that calculates the distances from the data points to each other and return the distances as a matrix.
	\item Get the distance matrix using the function \textit{distmat} mentioned above.
	\item Sort the distance matrix in ascending order.
	\item Take only the \textit{k}-nearest data points as neighbours for each data point.
	\item Calculate the mean from the distances of the \textit{k}-nearest neighbours and set it as the $\gamma$-index.
	\item Return the calculated $\gamma$-index as a \textit{1 x d} vector \textit{y}.
	
\end{enumerate}
